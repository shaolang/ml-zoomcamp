{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.10 Homework\n",
    "\n",
    "The goal of this homework is to create a tree-based regression model for prediction apartment prices (column `'price'`).\n",
    "\n",
    "In this homework we'll again use the New York City Airbnb Open Data dataset - the same one we used in homework 2 and 3.\n",
    "\n",
    "You can take it from [Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\n",
    "or download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\n",
    "if you don't want to sign up to Kaggle.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'neighbourhood_group', 'room_type', 'latitude', 'longitude',\n",
    "    'minimum_nights', 'number_of_reviews','reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365',\n",
    "    'price'\n",
    "]\n",
    "\n",
    "df = pd.read_csv('AB_NYC_2019.csv', usecols=columns)\n",
    "df.reviews_per_month = df.reviews_per_month.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Apply the log tranform to `price`\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainX_full, testX = train_test_split(df, test_size=0.2, random_state=1)\n",
    "trainX, valX = train_test_split(trainX_full, test_size=0.25, random_state=1)\n",
    "\n",
    "trainy, trainX = trainX['price'], trainX.drop('price', axis=1)\n",
    "valy, valX = valX['price'], valX.drop('price', axis=1)\n",
    "testy, testX = testX['price'], testX.drop('price', axis=1)\n",
    "\n",
    "trainy = np.log1p(trainy)\n",
    "valy = np.log1p(valy)\n",
    "testy = np.log1p(testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use `DictVectorizer` to turn train and validation into matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "trainX_encoded = dv.fit_transform(trainX.to_dict(orient='records'))\n",
    "valX_encoded = dv.transform(valX.to_dict(orient='records'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the price variable. \n",
    "\n",
    "* Train a model with `max_depth=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- room_type=Entire home/apt <= 0.50\n",
      "|   |--- value: [4.29]\n",
      "|--- room_type=Entire home/apt >  0.50\n",
      "|   |--- value: [5.15]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(max_depth=1)\n",
    "dt_reg.fit(trainX_encoded, trainy)\n",
    "\n",
    "print(export_text(dt_reg, feature_names=dv.feature_names_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `room_type`\n",
    "* `neighbourhood_group`\n",
    "* `number_of_reviews`\n",
    "* `reviews_per_month`\n",
    "\n",
    "**Answer:** `room_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1`  (optional - to make training faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.462"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def random_forest_rmse(n_estimators=10, max_depth=None):\n",
    "    rf_reg = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=1, n_jobs=-1)\n",
    "    rf_reg.fit(trainX_encoded, trainy)\n",
    "    predictions = rf_reg.predict(valX_encoded)\n",
    "\n",
    "    return np.sqrt(mean_squared_error(predictions, valy)).round(3)\n",
    "\n",
    "random_forest_rmse(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.059\n",
    "* 0.259\n",
    "* 0.459\n",
    "* 0.659"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10\n",
    "* Set `random_state` to `1`\n",
    "* Evaluate the model on the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10: 0.462\n",
      " 20: 0.448\n",
      " 30: 0.446\n",
      " 40: 0.444\n",
      " 50: 0.442\n",
      " 60: 0.442\n",
      " 70: 0.441\n",
      " 80: 0.441\n",
      " 90: 0.441\n",
      "100: 0.44\n",
      "110: 0.439\n",
      "120: 0.439\n",
      "130: 0.439\n",
      "140: 0.439\n",
      "150: 0.439\n",
      "160: 0.439\n",
      "170: 0.439\n",
      "180: 0.439\n",
      "190: 0.439\n",
      "200: 0.439\n"
     ]
    }
   ],
   "source": [
    "for n in range(10, 201, 10):\n",
    "    print(f'{n:-3d}: {random_forest_rmse(n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "\n",
    "- 10\n",
    "- 50\n",
    "- 70\n",
    "- 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "* Fix the random seed: `random_state=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 0.44, 15: 0.436, 20: 0.438, 25: 0.439}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{max_depth: min([random_forest_rmse(n, max_depth) for n in range(10, 201, 10)])\n",
    "         for max_depth in [10, 15, 20, 25]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best `max_depth`:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25\n",
    "\n",
    "Bonus question (not graded):\n",
    "\n",
    "Will the answer be different if we change the seed for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. \n",
    "When doing\n",
    " it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the imporatant features \n",
    "for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the `feature_importances_` field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parametes:\n",
    "    * `n_estimators=10`,\n",
    "    * `max_depth=20`,\n",
    "    * `random_state=1`,\n",
    "    * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          room_type=Entire home/apt: 0.392\n",
      "                          longitude: 0.154\n",
      "                           latitude: 0.153\n",
      "                   availability_365: 0.076\n",
      "                  reviews_per_month: 0.054\n",
      "                     minimum_nights: 0.053\n",
      "                  number_of_reviews: 0.042\n",
      "      neighbourhood_group=Manhattan: 0.034\n",
      "     calculated_host_listings_count: 0.030\n",
      "              room_type=Shared room: 0.005\n",
      "             room_type=Private room: 0.004\n",
      "         neighbourhood_group=Queens: 0.001\n",
      "       neighbourhood_group=Brooklyn: 0.001\n",
      "          neighbourhood_group=Bronx: 0.000\n",
      "  neighbourhood_group=Staten Island: 0.000\n"
     ]
    }
   ],
   "source": [
    "rf_reg2 = RandomForestRegressor(n_estimators=10, max_depth=20, random_state=1)\n",
    "rf_reg2.fit(trainX_encoded, trainy)\n",
    "\n",
    "for x in sorted(zip(dv.feature_names_, rf_reg2.feature_importances_), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{x[0]:>35s}: {x[1]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the most important feature? \n",
    "\n",
    "* `neighbourhood_group=Manhattan`\n",
    "* `room_type=Entire home/apt`\t\n",
    "* `longitude`\n",
    "* `latitude`\n",
    "\n",
    "**Answer:** `room_type=Entire home/apt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_gradient_boost_model(dmX, watchlist, eta=0.3):\n",
    "    xgb_params = {\n",
    "        'eta': eta, \n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 1,\n",
    "        'objective': 'reg:squarederror',\n",
    "        'nthread': 8,\n",
    "        'seed': 1,\n",
    "        'verbosity': 1,\n",
    "    }\n",
    "\n",
    "    return xgb.train(xgb_params, dmX, evals=watchlist, verbose_eval=5, num_boost_round=100)\n",
    "\n",
    "dm_trainX = xgb.DMatrix(trainX_encoded, label=trainy, feature_names=dv.feature_names_)\n",
    "dm_valX = xgb.DMatrix(valX_encoded, label=valy, feature_names=dv.feature_names_)\n",
    "watchlist = [(dm_trainX, 'train'), (dm_valX, 'validation')]\n",
    "\n",
    "train_gradient_boost_model(dm_trainX, watchlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    _num, train, val = line.split('\\t')\n",
    "    return (float(train.split(':')[1]), float(val.split(':')[1]))\n",
    "\n",
    "def parse_xgb_output(output, eta):\n",
    "    return pd.DataFrame([parse_line(line) for line in output.stdout.strip().split('\\n')],\n",
    "                        columns=[f'train_rmse;eta={eta}', f'val_rmse;eta={eta}'])\n",
    "\n",
    "rmse_eta_03 = parse_xgb_output(output, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change `eta` first to `0.1` and then to `0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "train_gradient_boost_model(dm_trainX, watchlist, eta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_eta_01 = parse_xgb_output(output, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "train_gradient_boost_model(dm_trainX, watchlist, eta=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_eta_001 = parse_xgb_output(output, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_rmse;eta=0.3</th>\n",
       "      <th>val_rmse;eta=0.3</th>\n",
       "      <th>train_rmse;eta=0.1</th>\n",
       "      <th>val_rmse;eta=0.1</th>\n",
       "      <th>train_rmse;eta=0.01</th>\n",
       "      <th>val_rmse;eta=0.01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.02752</td>\n",
       "      <td>3.02415</td>\n",
       "      <td>3.87217</td>\n",
       "      <td>3.86889</td>\n",
       "      <td>4.25336</td>\n",
       "      <td>4.25010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.67490</td>\n",
       "      <td>0.67752</td>\n",
       "      <td>2.31905</td>\n",
       "      <td>2.31692</td>\n",
       "      <td>4.04779</td>\n",
       "      <td>4.04454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.43912</td>\n",
       "      <td>0.44981</td>\n",
       "      <td>1.41910</td>\n",
       "      <td>1.41786</td>\n",
       "      <td>3.85242</td>\n",
       "      <td>3.84921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.42259</td>\n",
       "      <td>0.43827</td>\n",
       "      <td>0.91299</td>\n",
       "      <td>0.91348</td>\n",
       "      <td>3.66674</td>\n",
       "      <td>3.66359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.41716</td>\n",
       "      <td>0.43691</td>\n",
       "      <td>0.64528</td>\n",
       "      <td>0.64883</td>\n",
       "      <td>3.49030</td>\n",
       "      <td>3.48719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.41365</td>\n",
       "      <td>0.43621</td>\n",
       "      <td>0.51733</td>\n",
       "      <td>0.52364</td>\n",
       "      <td>3.32263</td>\n",
       "      <td>3.31956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.40712</td>\n",
       "      <td>0.43543</td>\n",
       "      <td>0.46186</td>\n",
       "      <td>0.47101</td>\n",
       "      <td>3.16332</td>\n",
       "      <td>3.16029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.40444</td>\n",
       "      <td>0.43510</td>\n",
       "      <td>0.43843</td>\n",
       "      <td>0.44997</td>\n",
       "      <td>3.01196</td>\n",
       "      <td>3.00898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.40103</td>\n",
       "      <td>0.43466</td>\n",
       "      <td>0.42770</td>\n",
       "      <td>0.44150</td>\n",
       "      <td>2.86817</td>\n",
       "      <td>2.86533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.39723</td>\n",
       "      <td>0.43371</td>\n",
       "      <td>0.42222</td>\n",
       "      <td>0.43795</td>\n",
       "      <td>2.73158</td>\n",
       "      <td>2.72884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.39446</td>\n",
       "      <td>0.43384</td>\n",
       "      <td>0.41868</td>\n",
       "      <td>0.43589</td>\n",
       "      <td>2.60185</td>\n",
       "      <td>2.59925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.39129</td>\n",
       "      <td>0.43378</td>\n",
       "      <td>0.41644</td>\n",
       "      <td>0.43515</td>\n",
       "      <td>2.47865</td>\n",
       "      <td>2.47612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.38743</td>\n",
       "      <td>0.43404</td>\n",
       "      <td>0.41432</td>\n",
       "      <td>0.43460</td>\n",
       "      <td>2.36167</td>\n",
       "      <td>2.35927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.38421</td>\n",
       "      <td>0.43450</td>\n",
       "      <td>0.41226</td>\n",
       "      <td>0.43400</td>\n",
       "      <td>2.25061</td>\n",
       "      <td>2.24835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.38117</td>\n",
       "      <td>0.43467</td>\n",
       "      <td>0.41059</td>\n",
       "      <td>0.43361</td>\n",
       "      <td>2.14519</td>\n",
       "      <td>2.14303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.37801</td>\n",
       "      <td>0.43489</td>\n",
       "      <td>0.40876</td>\n",
       "      <td>0.43336</td>\n",
       "      <td>2.04514</td>\n",
       "      <td>2.04311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.37668</td>\n",
       "      <td>0.43526</td>\n",
       "      <td>0.40747</td>\n",
       "      <td>0.43306</td>\n",
       "      <td>1.95022</td>\n",
       "      <td>1.94827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.37259</td>\n",
       "      <td>0.43537</td>\n",
       "      <td>0.40626</td>\n",
       "      <td>0.43299</td>\n",
       "      <td>1.86015</td>\n",
       "      <td>1.85833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.36998</td>\n",
       "      <td>0.43539</td>\n",
       "      <td>0.40478</td>\n",
       "      <td>0.43280</td>\n",
       "      <td>1.77472</td>\n",
       "      <td>1.77302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.36742</td>\n",
       "      <td>0.43579</td>\n",
       "      <td>0.40406</td>\n",
       "      <td>0.43272</td>\n",
       "      <td>1.69373</td>\n",
       "      <td>1.69214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.36478</td>\n",
       "      <td>0.43621</td>\n",
       "      <td>0.40277</td>\n",
       "      <td>0.43250</td>\n",
       "      <td>1.63198</td>\n",
       "      <td>1.63045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_rmse;eta=0.3  val_rmse;eta=0.3  train_rmse;eta=0.1  \\\n",
       "0              3.02752           3.02415             3.87217   \n",
       "1              0.67490           0.67752             2.31905   \n",
       "2              0.43912           0.44981             1.41910   \n",
       "3              0.42259           0.43827             0.91299   \n",
       "4              0.41716           0.43691             0.64528   \n",
       "5              0.41365           0.43621             0.51733   \n",
       "6              0.40712           0.43543             0.46186   \n",
       "7              0.40444           0.43510             0.43843   \n",
       "8              0.40103           0.43466             0.42770   \n",
       "9              0.39723           0.43371             0.42222   \n",
       "10             0.39446           0.43384             0.41868   \n",
       "11             0.39129           0.43378             0.41644   \n",
       "12             0.38743           0.43404             0.41432   \n",
       "13             0.38421           0.43450             0.41226   \n",
       "14             0.38117           0.43467             0.41059   \n",
       "15             0.37801           0.43489             0.40876   \n",
       "16             0.37668           0.43526             0.40747   \n",
       "17             0.37259           0.43537             0.40626   \n",
       "18             0.36998           0.43539             0.40478   \n",
       "19             0.36742           0.43579             0.40406   \n",
       "20             0.36478           0.43621             0.40277   \n",
       "\n",
       "    val_rmse;eta=0.1  train_rmse;eta=0.01  val_rmse;eta=0.01  \n",
       "0            3.86889              4.25336            4.25010  \n",
       "1            2.31692              4.04779            4.04454  \n",
       "2            1.41786              3.85242            3.84921  \n",
       "3            0.91348              3.66674            3.66359  \n",
       "4            0.64883              3.49030            3.48719  \n",
       "5            0.52364              3.32263            3.31956  \n",
       "6            0.47101              3.16332            3.16029  \n",
       "7            0.44997              3.01196            3.00898  \n",
       "8            0.44150              2.86817            2.86533  \n",
       "9            0.43795              2.73158            2.72884  \n",
       "10           0.43589              2.60185            2.59925  \n",
       "11           0.43515              2.47865            2.47612  \n",
       "12           0.43460              2.36167            2.35927  \n",
       "13           0.43400              2.25061            2.24835  \n",
       "14           0.43361              2.14519            2.14303  \n",
       "15           0.43336              2.04514            2.04311  \n",
       "16           0.43306              1.95022            1.94827  \n",
       "17           0.43299              1.86015            1.85833  \n",
       "18           0.43280              1.77472            1.77302  \n",
       "19           0.43272              1.69373            1.69214  \n",
       "20           0.43250              1.63198            1.63045  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.c_[rmse_eta_03, rmse_eta_01, rmse_eta_001],\n",
    "             columns=rmse_eta_03.columns.tolist() + rmse_eta_01.columns.tolist() + rmse_eta_001.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the best eta?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the results\n",
    "\n",
    "\n",
    "Submit your results here: https://forms.gle/wQgFkYE6CtdDed4w8\n",
    "\n",
    "It's possible that your answers won't match exactly. If it's the case, select the closest one.\n",
    "\n",
    "\n",
    "## Deadline\n",
    "\n",
    "\n",
    "The deadline for submitting is 20 October 2021, 17:00 CET (Wednesday). After that, the form will be closed.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
